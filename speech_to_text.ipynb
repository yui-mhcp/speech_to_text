{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for the `Speech-To-Text (STT)` API\n",
    "\n",
    "This notebook illustrates how to build a pretrained `Whisper` model, and use it to transcribe an audio file !\n",
    "\n",
    "Models are converted, from either the official `openai` checkpoints, either from the `transformers` models checkpoints, from `pytorch` to a `keras` instance. For this purpose, both your keras backend, and `torch` have to be installed. Once the model has been converted, `torch` is not required anymore ;) \n",
    "\n",
    "The `tts` method works on both audios and videos !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build whisper\n",
    "\n",
    "[Whisper](https://github.com/openai/whisper) is a multilingual `Speech-to-Text` model trained by `OpenAI`.\n",
    "\n",
    "**Note** : `pytorch` is required to convert the official `pytorch` checkpoint to a `keras` checkpoint ;)\n",
    "\n",
    "**Note** : the tokenizer is now copied from the `transformers` library, as the new official `openai`'s code is using their custom `tiktoken` tokenizer. This means that the 2 tokenizers are not *exactly* identical, but are compatible as the differences do not have any impact on the model.\n",
    "\n",
    "There is 2 supported versions of `Whisper` for inference :\n",
    "- The `keras` implementation provided in `architectures/transformers/whisper_arch.py`\n",
    "- The [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) implementation\n",
    "\n",
    "To get the best inference performances, the second option is the best one. The first implementation in `keras` is still maintained as it is a good way to effectively understand how `Whisper` is implemented, and working. It is worth mentioning that the provided `keras` implementation is faster than the `pytorch` implementation from the `transformers` library, as it leverages the `tensorflow XLA` optimization !\n",
    "\n",
    "The convertion to `TensorRT-LLM` is however a bit more complex, and require some additional configurations. Check the [installation guide](https://github.com/yui-mhcp/blob/master/INSTALLATION.md) to properly configure the libraries, then follow the steps below to build the TensorRT-LLM engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convertion to `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== whisper-base ==========\n",
      "Model :\n",
      "- Inputs \t: unknown\n",
      "- Outputs \t: unknown\n",
      "- Number of layers \t: 2\n",
      "- Number of parameters \t: 71.826 Millions\n",
      "- Model not compiled yet\n",
      "\n",
      "Transfer-learning from : base\n",
      "Already trained on 0 epochs (0 steps)\n",
      "\n",
      "- Language : multi\n",
      "- Vocabulary (size = 50364) : ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ...]\n",
      "- Audio rate : 16000\n",
      "- # mel channels : 80\n",
      "- Use CTC decoder : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.stt import Whisper\n",
    "\n",
    "model = Whisper(pretrained = 'base', lang = 'multi', nom = 'whisper-base')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion to `TensorRT-LLM`\n",
    "\n",
    "**WARNING** The `TensorRT-LLM` engines are specific to a version of the library, meaning that if you update the `TensorRT-LLM` library, you will have to re-build the engine. Furthermore, the current `convert_checkpoint` scripts in the official `TensorRT-LLM` repository only supports official `Whisper` implementations by `OpenAI`, and not the versions from the `transformers` library. This is the reason why I provide a custom `convert_checkpoint.py` script that supports these custom models !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : loading the pre-trained pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSpeechSeq2Seq\n",
    "\n",
    "model_name = 'bofenghuang/whisper-large-v3-french'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModelForSpeechSeq2Seq.from_pretrained(model_name, device_map = 'cuda', torch_dtype = 'float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : build the `TensorRT-LLM` engine\n",
    "\n",
    "The below script displays the commands to execute in the `TensorRT-LLM/examples/whisper` directory.\n",
    "\n",
    "1. Clone the official repository\n",
    "\n",
    "`git clone https://github.com/NVIDIA/TensorRT-LLM`\n",
    "\n",
    "2. Navigate to the directory, and copy the provided weights convertion script\n",
    "\n",
    "```bash\n",
    "cp convert_checkpoint-0.19.py TensorRT-LLM/examples/models/core/whisper/convert_checkpoint.py\n",
    "cd TensorRT-LLM/examples/models/core/whisper\n",
    "```\n",
    "\n",
    "3. Set the desired model to convert, then display the commands to execute\n",
    "4. Run the commands in your python virtual environment\n",
    "\n",
    "**Note** : the parameters in the below commands have been optimized to use the less possible memory in a single inference use-case. If you plan to use the model via an API server, you may need to increase the batch_size to support multiple requests in parallel !\n",
    "\n",
    "**Note** : the engines are specific to a `TensorRT-LLM` version, and should be re-built when updating the library. In order to make it as generic as possible, these commands store the engines in a special cache directory `~/.cache/tensorrt_llm/[version]`. The `get_module_version` allows to get the module's version without importing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from utils import get_module_version\n",
    "\n",
    "model_name = 'bofenghuang/whisper-large-v3-french'\n",
    "\n",
    "cache_dir = os.path.expanduser('~/.cache/tensorrt_llm/{}'.format(get_module_version('tensorrt_llm')))\n",
    "\n",
    "if 'openai' not in model_name:\n",
    "    hf_path = os.path.dirname(\n",
    "        glob.glob(os.path.expanduser('~/.cache/huggingface/hub/models--{}/snapshots/**/config.json'.format(model_name.replace('/', '--'))))[0]\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "model_path = model_name.split('/')[1].replace('-', '_')\n",
    "if cache_dir: model_path = os.path.join(cache_dir, model_path)\n",
    "\n",
    "int8 = True\n",
    "batch_size = 1\n",
    "\n",
    "if int8: model_path += '_int8'\n",
    "\n",
    "cmd1 = \"\"\"\n",
    "python convert_checkpoint.py \\\\\n",
    "    --model_dir {} \\\\\n",
    "    --output_dir {}_checkpoint \\\\\n",
    "    --dtype float16\n",
    "\"\"\".format(hf_path, model_path)\n",
    "if int8: cmd1 = cmd1.strip() + \" \\\\\\n    --use_weight_only \\\\\\n    --weight_only_precision int8\"\n",
    "\n",
    "cmd2 = \"\"\"\n",
    "trtllm-build --checkpoint_dir {model_path}_checkpoint/encoder \\\\\n",
    "             --output_dir {model_path}_engine/encoder \\\\\n",
    "             --max_batch_size {batch_size} \\\\\n",
    "             --max_seq_len 3000 \\\\\n",
    "             --max_input_len 3000 \\\\\n",
    "             --max_encoder_input_len 3000 \\\\\n",
    "             --kv_cache_type disabled\n",
    "\"\"\".format(model_path = model_path, batch_size = batch_size)\n",
    "\n",
    "cmd3 = \"\"\"\n",
    "trtllm-build --checkpoint_dir {model_path}_checkpoint/decoder \\\\\n",
    "             --output_dir {model_path}_engine/decoder \\\\\n",
    "             --max_batch_size {batch_size} \\\\\n",
    "             --max_beam_width 5 \\\\\n",
    "             --max_encoder_input_len 3000 \\\\\n",
    "             --max_input_len 4 \\\\\n",
    "             --max_seq_len 512 \\\\\n",
    "             --tokens_per_block 16\n",
    "\"\"\".format(model_path = model_path, batch_size = batch_size)\n",
    "\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "print(cmd3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : building the `Whisper` instance\n",
    "\n",
    "The `BaseModel` class (the base class for the `Whisper` implementation) supports the `TensorRT-LLM` runtime, by specifying the `runtime` argument (in this case : `trt_llm`). This runtime requires the `path` argument, specifying the path to the runtime engine. The `kv_cache_free_gpu_memory` is a convenient feature I have added, which internally uses the `kv_cache_free_gpu_memory_fraction` from the `TRT-LLM` framework, limiting the memory used by the model buffers. This is based on estimations to convert the absolute value to the *free_memory_fraction*, but is still more convenient than manually estimating the fraction ;)\n",
    "\n",
    "**Important note** : the `TensorRT-LLM` implementation uses a custom GPU memory manager, it is the reason why it is important to limit the visible gpu memory for `tensorflow`, to leave spaces to `TensorRT-LLM` ! `tensorflow` is used to compute the mel-spectrogram (the input of `whisper`), and therefore requires to be initialized. Another solution is to switch the `keras` backend to `pytorch`, but it is not always possible nor profitable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loggers import *\n",
    "from models.stt import Whisper\n",
    "from utils import get_module_version, setup_environment\n",
    "\n",
    "setup_environment(gpu_memory = 512)\n",
    "\n",
    "int8 = True\n",
    "\n",
    "STT_MODEL   = 'bofenghuang/whisper-large-v3-french'\n",
    "STT_NAME    = STT_MODEL.split('/')[1].replace('-', '_')\n",
    "if int8: STT_NAME += '_int8'\n",
    "STT_ENGINE  = os.path.expanduser('~/.cache/tensorrt_llm/{}/{}_engine'.format(get_module_version('tensorrt_llm'), STT_NAME))\n",
    "\n",
    "model = Whisper(\n",
    "    name = 'trtllm-{}_{}'.format(get_module_version('tensorrt_llm'), STT_NAME),\n",
    "    pretrained = STT_MODEL,\n",
    "    \n",
    "    path = STT_ENGINE,\n",
    "    runtime = 'trt_llm',\n",
    "    max_batch_size = 1,\n",
    "    kv_cache_free_gpu_memory = 512\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction API\n",
    "\n",
    "The prediction API is very simple to use : pass the audio filename(s), and the model you want (or the audio language) and that's it !\n",
    "\n",
    "The prediction splits the audio into *chunks* of a given amount of time (default to 30sec), and predicts the text for each chunk. Then it concatenates all the texts to build the complete transcription of the audio file ! Note that `Whisper` also splits each chunk into frames corresponding to the timestamps of the transcription (these are provided in the output). This may be useful to search a span of text, or even complete / correct the transcription ! \n",
    "\n",
    "This demonstration is performed on a short and clean audio. Nevertheless, `Whisper` has been trained on large scale datasets, and is able to transcribe audios in many languages, even in noisy or low quality audios !\n",
    "\n",
    "`Whisper` is a multilingual model, meaning that it can transcribe audios from a large variety of languages. However, it has to know which language it should use. To this end, the 1st prediction step is to detect the language from the audio. To skip this part, and thus speed up the prediction time, you can provide the `lang` argument ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timers :\n",
      "- predict : 65 ms\n",
      "  - predict : 65 ms\n",
      "    - inference : 65 ms\n",
      "      - loading audio : 46 ms\n",
      "        - read_audio : 45 ms\n",
      "          - read file : 44 ms\n",
      "          - normalize_audio : 385 μs\n",
      "          - trim_silence : 207 μs\n",
      "        - mel spectrogram : 1.319 ms\n",
      "          - graph_mel_spectrogram : 812 μs\n",
      "      - segment processing : 437 μs\n",
      "      - xla_infer : 17 ms\n",
      "      - post_processing : 100 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': '<|notimestamps|> The streets were narrow and unpaid but very fairly clean.',\n",
       "  'segments': [{'start': 0.0,\n",
       "    'end': 3.96,\n",
       "    'text': '<|notimestamps|> The streets were narrow and unpaid but very fairly clean.',\n",
       "    'tokens': array([  440,  8481,   645,  9432,   293,   517, 35035,   457,   588,\n",
       "            6457,  2541,    13], dtype=int32),\n",
       "    'lang': 'en',\n",
       "    'time': 3.96}],\n",
       "  'lang': 'en',\n",
       "  'filename': 'audio_en.wav'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loggers import set_level\n",
    "from models.stt import transcribe\n",
    "from utils.audio import display_audio\n",
    "\n",
    "set_level('time')\n",
    "\n",
    "filename = 'audio_en.wav'\n",
    "pred = transcribe(filename, model = 'whisper-base', save = False, lang = 'en', display = False)\n",
    "\n",
    "#display_audio(filename)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT-LLM inference\n",
    "\n",
    "The `transcribe` method is the same for all the supported models. Simply provide the `model`'s name, and it will be automatically loaded, no matter it is a `keras` or `TensorRT-LLM`-based model ;)\n",
    "\n",
    "**Note** : It is worth mentioning that, in the above example, the `whisper-base` model is used, while in the below cell, it is a fine-tuned version of the `large-v3` model. The inference time are therefore **not** comparable, as the last one is **much bigger**. \n",
    "\n",
    "**Known limitation** : currently, the `Whisper` engine predicts by default 1 token, no matter the parameters given to the build method. To overcome this, it is required to manually specify the `max_new_tokens` argument. In addition to that, the warnings displayed about the `CrossAttentionMask` were not displayed in the `v0.14`, but are actually not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory limited to 512Mb\n",
      "[TensorRT-LLM][WARNING] Default padding attention mask will be used as not all requests have cross attention mask.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the request. Default padding attention mask will be created.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TensorRT-LLM][WARNING] CrossAttentionMask is not provided for the generation request. Full valid attentionMask will be used by default.\n",
      "[TRT-LLM] 14 tokens generated in 96 ms (144.351 tokens/sec)\n",
      "Timers :\n",
      "- predict : 173 ms\n",
      "  - predict : 173 ms\n",
      "    - inference : 173 ms\n",
      "      - loading audio : 74 ms\n",
      "        - read_audio : 61 ms\n",
      "          - read file : 61 ms\n",
      "          - normalize_audio : 238 μs\n",
      "          - trim_silence : 241 μs\n",
      "        - mel spectrogram : 12 ms\n",
      "          - graph_mel_spectrogram : 1.071 ms\n",
      "      - segment processing : 412 μs\n",
      "      - TRT-LLM inference : 98 ms\n",
      "      - post_processing : 143 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'The streets were narrow and unpaved, but very fairly clean.',\n",
       "  'segments': [{'start': 0.0,\n",
       "    'end': 3.96,\n",
       "    'text': 'The streets were narrow and unpaved, but very fairly clean.',\n",
       "    'tokens': array([ 2278,  8481,   645,  9432,   293, 20994, 12865,    11,   457,\n",
       "             588,  6457,  2541,    13], dtype=int32),\n",
       "    'lang': 'en',\n",
       "    'time': 3.96}],\n",
       "  'lang': 'en',\n",
       "  'filename': 'audio_en.wav'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loggers import set_level\n",
    "from models.stt import transcribe\n",
    "from utils.audio import display_audio\n",
    "from utils import get_module_version, setup_environment\n",
    "\n",
    "setup_environment(gpu_memory = 512)\n",
    "\n",
    "set_level('time')\n",
    "\n",
    "filename = 'audio_en.wav'\n",
    "pred = transcribe(\n",
    "    filename, model = 'trtllm-{}_whisper_large_v3_french_int8'.format(get_module_version('tensorrt_llm')),\n",
    "    save = False, lang = 'en', display = False, max_new_tokens = 128\n",
    ")\n",
    "\n",
    "#display_audio(filename)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search keyword in audio\n",
    "\n",
    "**This feature comes from an older version and is not working anymore. This will be updated for the next release**\n",
    "\n",
    "The `search` function allows to search a keyword in an audio / video, and get all timestamps where this keyword has been found (with a given probability threshold). Even though the model is quite accurate, it can make some spelling mistakes, like in the given audio (i.e., the *unpaid* should be *unpaved*). To mitigate this in the matching function, the `Edit` distance (aka `Levenshtein distance`) is used with a *partial* alignment to find all occurences with a given tolerance. \n",
    "\n",
    "Once the positions of the candidates have been found, its approximate timestamp is provided based on its relative position, and the time information of the segments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name : whisper-base\n",
      "Result for searching keyword 'clean' :\n",
      "Number of files : 1 / 1\n",
      "Total number of occurences : 1\n",
      "Files : Annotation of file audio_en.wav :\n",
      "- Total annotation time : 30.000 sec\n",
      "- Number of alignments : 1 (1 sub-parts)\n",
      "- Speakers (n = 1) : [-1]\n",
      "\n",
      "Occurences of 'clean' (1, threshold = 80.00%) :\n",
      "- Timestamp 26.316 sec (p = 100.00 %) : [...]  clean. [...]\n",
      "\n",
      "pretrained_models/whisper-base/search/map.json\n",
      "Filename is in processed file : False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from utils import load_json\n",
    "from models import get_model_dir\n",
    "from models.stt import search, get_model_name\n",
    "\n",
    "model_name = 'whisper-base'\n",
    "filename = 'audio_en.wav'\n",
    "\n",
    "print(\"Model name : {}\".format(model_name))\n",
    "r = search('clean', filename, model = model_name)\n",
    "print(r)\n",
    "print(get_model_dir(model_name, 'search', 'map.json'))\n",
    "print(\"Filename is in processed file : {}\".format(filename in load_json(get_model_dir(model_name, 'outputs', 'map.json'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.display(before = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit distance demonstration\n",
    "\n",
    "This example illustrates with longer example the **edit distance** with partial alignment for searching keyword in bad-spelled text (as described in the README file). \n",
    "\n",
    "The objective is to find *cat* in the text *the ct is here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance without partial alignment :\n",
      "          t    h    e         c    t         i    s           h     e     r     e\n",
      "   0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  10.0  11.0  12.0  13.0  14.0\n",
      "c  1.0  1.0  2.0  3.0  4.0  4.0  5.0  6.0  7.0  8.0   9.0  10.0  11.0  12.0  13.0\n",
      "a  2.0  2.0  2.0  3.0  4.0  5.0  5.0  6.0  7.0  8.0   9.0  10.0  11.0  12.0  13.0\n",
      "t  3.0  2.0  3.0  3.0  4.0  5.0  5.0  6.0  7.0  8.0   9.0  10.0  11.0  12.0  13.0\n",
      "Edit distance with partial alignment :\n",
      "          t    h    e         c    t         i    s         h    e    r    e\n",
      "   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "c  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "a  2.0  2.0  2.0  2.0  2.0  1.0  1.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0\n",
      "t  3.0  2.0  3.0  3.0  3.0  2.0  1.0  2.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
      "Best alignment :  ct\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from loggers import set_level\n",
    "from utils import plot, set_display_options\n",
    "from utils.text import edit_distance\n",
    "\n",
    "set_level('info')\n",
    "set_display_options()\n",
    "\n",
    "truth = 'the ct is here'\n",
    "hypothesis = 'cat'\n",
    "\n",
    "print(\"Edit distance without partial alignment :\")\n",
    "dist, matrix = edit_distance(hypothesis, truth, partial = False, return_matrix = True, normalize = False, verbose = True)\n",
    "\n",
    "print(\"Edit distance with partial alignment :\")\n",
    "partial_dist, partial_matrix = edit_distance(hypothesis, truth, partial = True, return_matrix = True, normalize = False, verbose = True)\n",
    "\n",
    "start_idx = np.argmin(partial_matrix[-1, 1:]) + 1 - len(hypothesis)\n",
    "print(\"Best alignment : {}\".format(truth[start_idx : start_idx + len(hypothesis)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPCklEQVR4nO3deXhU5d3/8U8SEvZsyCaVTSRBXEGLohSQHaQqrrXKYnFttVbtw+JOiwhSsFJRH60otL8qVeSxFSQEAgqoSA2KhbBI2EJAIHvInvv3R5LhTBZIhknOmZP367q+l3OfmTPznUmGfDzbHSTJCAAAAAEv2O4GAAAA4B8EOwAAAJcg2AEAALgEwQ4AAMAlCHYAAAAuQbADAABwCYIdAACASxDsAAAAXIJgBwAA4BKOCnbnn3++XnvtNSUmJqqoqEjbtm2r9bpTpkzR/v37dfLkSW3atEn9+vWrx04BAACcx1HBrnfv3hozZoz27Nmj7du313q9KVOm6Pnnn9f8+fN1/fXXKzU1VXFxcerWrVs9dgsAAOA8xikVFBTkub1o0SKzbdu2M67TtGlTk5GRYWbOnOlZFhoaapKTk82rr75q+3uiKIqiKIpqqHLUFjtjTJ3X6d+/vyIiIrR06VLPsqKiIi1btkyjR4/2Z3sAAACO5qhg54vY2FhJUlJSktfyHTt2qHPnzmrWrJkdbQEAADS4JnY3cLaioqKUn5+vgoICr+Xp6ekKDg5WVFSUUlNTq103LCxMTZs29YxLS0tVUFCg4uLieu0ZAACgPgT8FruzMW3aNGVlZXkqKSmJUAcAAAJWwAe79PR0NWvWzGvLm1S2Ja+0tFTp6ek1rjtr1iyFh4d7qmK3LgAAQCAK+GBXcWxdTEyM1/LY2FgdOHBA+fn5Na5bWFio7OxsT+Xm5tZrrwAAAPUp4IPdpk2blJmZqVtvvdWzrEmTJho3bpxWrFhhY2cAAAANy1EnTzRv3txziZIuXbooPDxcN998syRp/fr1On78uOLj49WlSxddcMEFkqSCggLNmjVLzz33nI4dO6Zt27bpoYceUps2bTR37lzb3gsAAIAdbL+YXkV16dLF1GTgwIFGkklISDDJyclV1p06dao5cOCAycvLM1988YW56qqrbH8/FEVRFEVRDVlB5TcAAAAQ4AL+GDsAAACUIdgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4hOOCXUxMjOLi4pSTk6PU1FTNnj1boaGhZ1wvOjpar732mvbv36+cnBxt27ZN999/fwN0DAAA4AxN7G7AKjIyUmvXrtXu3bs1btw4derUSfPmzVOLFi308MMPn3bdf/7zn4qNjdX06dN14MABjR49Wq+//rpKSkr01ltvNdA7AAAAsJdxSk2dOtVkZ2ebqKgoz7J7773XFBUVmY4dO9a4Xvv27Y0xxkyYMMFr+bp160x8fLzt74uiKIqiKKohylG7YkeNGqX4+Hilp6d7li1dulTBwcEaPnx4jetV7KrNzMz0Wp6ZmamgoKD6aRYAAMBhHBXsYmNjlZSU5LUsMzNTqampio2NrXG9Q4cOadWqVZo+fbp69eqlVq1a6dZbb9Xw4cP16quv1nfbAAAAjuCoY+yioqKUkZFRZXl6erqio6NPu+64ceP0/vvva/v27ZKk4uJiPfzww1q2bFmN64SFhalp06aesTFGOTk5vjUPAABgM0dtsTsbixYt0gUXXKBf/OIXGjRokGbPnq2XX35Zt99+e43rTJs2TVlZWZ5KSUlpwI4BAAD8z/YD/Srq6NGj5oUXXqiy/NChQ2bWrFk1rjdmzBhjjDEXXXSR1/L//d//NYcOHapxvbCwMNO6dWtPtWrVyvbPgKIoiqIoytdy1Ba7pKSkKsfShYeHq2PHjlWOvbO68MILVVxcrO+//95reWJiojp16qTmzZtXu15hYaGys7M9xW5YAAAQyBwV7FauXKmhQ4cqIiLCs+zWW29VaWmp4uLialxv//79atKkiS655BKv5X379tXRo0eVl5dXbz0DAAA4ie2bDSsqMjLSpKSkmISEBDNs2DAzceJEk5aWZhYsWOD1uPj4eLN7927PuFWrVmbfvn1m165d5pe//KW57rrrzIsvvmiKi4vNk08+afv7oiiKoiiKaqCyvQGvio2NNatXrza5ubnmyJEjZs6cOSY0NNTrMQkJCSY5Odlr2fnnn2/ee+89c+jQIZOTk2O2bdtmHnnkERMcHGz7e6IoiqIoimqICiq/AQAAgADnqGPsAAAA4DuCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsAAACXINgBAAC4BMEOAADAJQh2AAAALkGwAwAAcAmCHQAAgEsQ7AAAAFyCYAcAAOASBDsADaavpBWSFkoKs7kXAHCjJnY3AKDx+LukmPLb+yTNsa8VAHAlttgBaBAX6VSok6Rb7GoEAFzsrINdWFiYQkND/dELABcbU2l8paT2djQCAC5W52B36aWXaubMmdq4caMyMjJ08uRJ5eXlKSMjQxs2bNAf//hHXXbZZfXQKoBAVjnYSdKoBu8CANwtSJKpzQPHjBmjp59+WldccYWCgoK0b98+/fDDDzpx4oSCgoIUHR2tHj16qEuXLjLGaMuWLZoxY4ZWrFhRz28BgNNFSTomKaTS8g8k3drw7QCAq5kz1Zo1a0xxcbGJj483EyZMMO3atavxse3atTOTJk3yrLN69eozPj9FUe6uOyRjqqlMyYQ6oD+KoigX1Zkf9OGHH5qLL764zk9+6aWXmmXLltn9BimKsrmWqPpgZyQz2AH9URRFuaVqvSsWAHwRLOmopHPKxxsk9depA3z/JOkJG/oCADficicA6lU/nQp1krRY0leWcXUnVQAAfOOXCxR36tRJv/zlL3Xeeefp8OHDeu+995ScnOyPpwYQ4CoHtxWS2km6unwcK6m7pL0N2RQAuNRZ74odMGCAPv30Ux0/flyHDh3SBRdcoNatW+umm27Sp59+6qc2AQSqREmXld/eKuny8nGi5TGPSFrQkE0BgEuddbDbuHGj1qxZo2eeeUZS2QWLP/jgA3Xp0kWXXnqpP3oEEKA6STpkGc+U9FT57UPl90vSKkkjG7AvAHCrWh9jt2DBArVo0aLK8i5dumjZsmWecWFhoVasWKEuXbr4p0MAAWt0pfEnltvWK1wOktSy3rsBAPerdbDr37+/duzYoTFjvI+Y2bx5s55//nl17dpVTZo00eWXX67f/OY3+vrrr/3eLIDAYv3X4ri8T5qwhrymkoY0SEcA4H61uy5KUJB54oknTHZ2tnnvvfdM27ZtjSTzk5/8xHz33XemuLjYU0lJSaZHjx62X8uFoij7qqlkcnTqenVLKt3fUjL5lvvfcEDPFEVRLqi6rdCtWzezatUqc+LECXPPPfcYqSz0XX311eaWW24x/fv3NyEhIXa/KYqibK7h8r4Q8R3VPGaV5f6DDuiZoijKBeXbinfffbf58ccfzdq1a9k6R1FUlfqzToW2YslEVfOYR+Qd/i51QN8URVGBXD5foHjJkiW68MILlZKSom+//VbTpk1TSEjlKb4BNFbW4+s2SUqv5jGfVBpzsWIAODt1utxJp06dNGLECLVs2VJffPGFtmzZIkkaPny4XnvtNeXk5Gjy5MmcOAE0cjGSkizjqZJm1/DYpPLHS2UB8Jp67AsAGoNabdobPHiwycrKMjk5Oeb48eOmuLjYPPvss577mzdvbubOnWvy8/PNyy+/bFq0aGH75kiKouypx+S9i/Wi0zz2T5bHlUimjQP6pyiKCuCq3QO3bNliVq5caZo1a2YkmalTp5rCwkJzzjnneD2uT58+5j//+Y/Zt2+f3W+Moiibao1OhbX9Z3jsdfIOgb90QP8URVGBWrU+xq5nz55atmyZ8vPzJUl/+9vfFBISou7du3s97ptvvtGVV16pv/zlL7V9ai8xMTGKi4tTTk6OUlNTNXv2bIWGhtZq3XPPPVfvvPOOfvzxR508eVLbt2/XnXfe6VMfAHwTLmmAZVz5OLrKPpeUZRlznB0A+K5JbR+4e/du3XTTTXr33XdVWFioX/ziFyopKdHevVWn7i4tLdXcuXPr3ExkZKTWrl2r3bt3a9y4cerUqZPmzZunFi1a6OGHHz7tuh06dNAXX3yhnTt36r777lNWVpZ69+6tpk2b1rkPAL4bJsn6v2JnCnZFklZLurl8PFJSiKQS/7cGAI1CrTbtDR061OTk5Jjs7Gxz7NgxU1JSYp577jm/bj6cOnWqyc7ONlFRUZ5l9957rykqKjIdO3Y87bqLFy82GzZsMMHBwbZvBqWoxlxv69Ru1ZOSaV6LdSbJe3fstQ54HxRFUQFatX/weeedZ+69917zyCOPmCuvvNLvzaxfv9589NFHXssiIiJMSUmJmTBhQo3rtW7d2uTn55s777zT7g+Tohp1BUnmiE4FtE9quV57eQe7WQ54LxRFUYFYdbqO3cGDB/Xmm2/qlVdeqZdLmsTGxiopKclrWWZmplJTUxUbG1vjen369FHTpk1VVFSkdevWqbCwUKmpqXrxxRfVpEmt9zYDOEt9JbW3jM+0G7bCUUlbLGOOswMA3/h8geL6EBUVpYyMjCrL09PTFR0dXeN6HTp0kCS99dZb2rJli4YPH6758+fr0Ucf1YwZM2pcLywsTK1bt/ZUq1atzvo9AI3Z6Erj2ga7yo+9WNJ5Z98OADQ6tQp2n332mQYMGHDmB1YyePBgff7553Ver66Cg8veRnx8vJ544gmtW7dOc+bM0UsvvaTf/e53atasWbXrTZs2TVlZWZ5KSUmp914BN7NuafuvpP11WJdZKADg7NUq2B0+fFjr1q3Tli1b9PDDD6tHjx41PrZXr156/PHHtXXrVq1evVoHDhyodTPp6emKiIiosjwqKkppaWmnXU+S1q5d67V8zZo1atasWY39zpo1S+Hh4Z7q1KlTrXsF4K2dpJ9axnXZWieV7Yo9ahkT7ACg7mp1ANodd9yhV155Rc8884zmz5+v+fPnKyMjQ8nJyUpLS1NQUJCio6N1/vnnq3Xr1jLGaNWqVbr//vv11Vdf1bqZpKSkKsfShYeHq2PHjlWOvbPavn37aZ+3pi12hYWFKiwsrHV/AGo2qtK4rsHOSFopaWL5+DpJzSTln11bANDo1Olsi+7du5spU6aYTz75xCQnJ3sugbJ3717z8ccfm8cee8x06dLFpzM5pk6darKyskxERIRn2a9+9ataXe7k22+/rXJG7cyZM01ubi7Tm1FUA9RSnTqrNV0yTXx4jlvkfXbsKAe8L4qiqAAr2xvwVGRkpElJSTEJCQlm2LBhZuLEiSYtLc0sWLDA63Hx8fFm9+7dXsuuv/56U1JSYubPn2+GDh1qpk2bZgoKCswf/vAH298XRbm9mkgmQ6cC2Xs+Pk+4ZAotz/MXB7w3iqKoACvbG/Cq2NhYs3r1apObm2uOHDli5syZY0JDQ70ek5CQYJKTk6use9ttt5lt27aZ/Px8k5ycbKZOnWr7+6GoxlCD5L2l7e6zeK61ludJdsB7oyiKCqQKKr8BAD57SdIT5bdLVXYtu+M+PtfjkqwTEvaWdPqjaAEAFRx1HTsAgcl6Butm+R7qJC57AgBng2AH4Kx0k9TLMq7r2bCVJUnaaxkT7ACg9gh2AM5K5eB1tsGu8nNcIynSD88JAI0BwQ7AWbEGu8OSEv3wnNZg10TScD88JwA0Bj4Fu5ou+AugcWkhaZBlvMJPz7tOUq5lXHkOWgBA9XwKdqmpqVq4cKH69Onj734ABJAhKpsdooI/dsNKUoGkNZbxKElBfnpuAHAzn4Ldxo0bNXnyZG3evFmJiYn69a9/Xe0crwDczbobtlBSvB+f2xoS20m60o/PDQBu5VOwu/7669WlSxc988wzatWqlV555RUdPnxYf/vb3zRo0CA/twjAqay7SNdLyvHjc1fercvZsQBQO2d9leNBgwaZJUuWmNzcXFNcXGx2795tpk2bdsb5XSmKCty6RN6zTfy2Hl5jq+X5tzjgPVMURQVA+e/JwsPDzbvvvmtKSkpMcXGxKSgoMB999JG58sor7X6TFEX5uabJO9j1qIfXmFnpNTo44H1TFEU5ufxyuZPo6Gg9+uij2rhxo+666y7l5uZq0aJFevPNNzV48GBt2rRJkydP9sdLAXAI667RXZL21MNrVD4Zg7NjAeDMfE6FI0aMMEuXLjV5eXmmpKTEbNmyxdx///2mVatWnseEh4eb1atXm/3799ueYimK8k9FS6ZYp7akzaun1wmWzHHL63zogPdOURTl8Kr7SjNmzDD79+83xcXFJjMz07z++uumT58+NT7+rrvuMsXFxXa/UYqi/FR3ynsX6ZB6fK2/WV4nSzJhDnj/FEVRDq66r1RSUmI2b95sJk+ebFq0aHHGx1944YXmmWeesfuNUhTlp/q7ToWtbNVv2GrIEElRFBXoFVR+o04uvfRSffvtt3VdDYALhEj6UVJ0+fgjSePq8fWiy18vpHw8X9Jj9fh6ABDIfDp5Yt68ebruuutqvH/QoEFas2ZNjfcDCFxX6VSok/w320RN0iR9aRlzPTsAqJlPwW7QoEFq3759jfe3a9dOAwcO9LkpAM5VOVj5a37Y07GGx56SejTAawJAIPLL5U4qi4yMVEFBQX08NQCbWYPdN5JSG+A1K28VZKsdAFSvSW0fePHFF+uyyy7zjAcMGKAmTaquHh0drYceekjbt2/3S4MAnOM8SZdYxvW9G7bCd5IOlr++VBbs/txArw0AgaZWZ1k888wzpqSkxDOrRMXt6iojI8OMGDHC9jNDKIryb90v7zNU+zXga79ued0CybRywOdBURTltKr1WbGdO3dW165dFRQUpLVr1+qFF17Q6tWrvR5jjFFOTo62b9/OrljAhT6WNLb89jFJHSSVNtBrjy1//Qo3SVreQK8NAIHCp8udjB8/Xp999pn27dvn/44AOFIzSScktSgfL5Y0oQFfv0X56zcrH78l6d4GfH0ACAQ+BTsAjc9ISSst49slLW3gHlaW9yFJhyV1auDXBwCnq9XJE3fffbckacmSJV7jM6l4PIDAZz0TtVjSKht6+ESngt25ki6XlGhDHwDgVLXaYldSUiJjjJo3b66ioiLPOCgoqMZ1jDHVnjULIDDtldSt/PZ6SYNs6KFbeR8Vnpb0Rxv6AACnqlXyGjx4sCSpqKjIawygceilU6FOarjLnFSWLGmHyvqRyrYiEuwA4BSOsQNwRk9Iesky7i3JritVvqSyfqSyM3LbSzpuUy8A4DT1MvMEAHexHl+3T/aFOsl7a2GwpFF2NQIADlSrXbEDBgzw6ck///xzn9YD4BwRkq61jO3aDVthg6RMlfUllYVOTtMCgDJ1Onmi1k8aFMTJE4BL3Crvy5qMlvdlT+ywVGV9SVKGpLYqO1MXABq7WiWvSZMm1XcfABzKuhv2pKQEuxqx+ESngl2kpP6SPrOtGwBwDk6eAFCjIElHJLUrH/9bp6YUs1M7SUct4zmSptjUCwA4CSdPAKjRlToV6iT7j6+r8KOkzZbxmJoeCACNTK12xZ533nmSpIMHD3qNz6Ti8QAC0+hKY6cEO6msl5+W3+4tqYuk/fa1AwCOUOuTJ0pLS9WiRQuvmSfOhJMngMD2taQrym9vk3SJjb1U1lfSFsv415IW2tQLADhFrZLXjBkzZIxRcXGx1xiAe3XQqVAnOWtrnSR9o7Lj/zqUj8eIYAcAnDwBoFqTJL1tGQ9Q2TXknOSvku4pv50nqU35fwGgseLkCQDVsp6QkCbpC7saOQ3rVsTmkq6zqxEAcIizOgjuyiuv1E033aTu3btLkvbu3avly5dr8+bNZ1gTgJOFShpmGa+SVGJTL6ezWlKhpLDy8Rg5b5cxADQ0U9cKDg42b731likuLjYlJSVeVVxcbN5++20THBxc5+elKMoZdZ1kjKV+6YCeaqp4S5/7HdAPRVGUneXTrtinnnpKkyZN0v/93/+pf//+ioyMVGRkpK655hp9/PHHGj9+vJ566ilfnhqAA1h3w5ZK+tSuRmrBuoWus6SL7GoEABzAp5Mn9u3bp6SkJI0cObLa++Pi4tSzZ0917dr1LNsDYIckSTHltzdJusbGXs6kp6SdlvFUSbNt6gUA7ObTFrt27drp448/rvH+5cuXq127djXeD8C5ztepUCc5/5i1XZL2WMbMQgGgMfMp2O3atUsdOnSo8f6OHTtq165dPjcFwD6Vg5HTg53k3WN/SVF2NQIADlDnA/Nuv/12c+LECXPJJZdUue+yyy4zJ06cMLfddpvtBxBSFFX3WqVTJyMcdEA/talh8j7Z4w4H9ERRFGVH1epyJ08//XSVZcnJydqyZYvi4uKUlJQkSerVq5eGDRumb7/9Vj179qzNUwNwkJaSBlrGK+xqpI7WS8qR1Kp8PEbSe/a1AwC2qfVcsXVljGGuWCDA3CBpeaVxzUfTOstHkm4sv31cUnuVndELAI1JrZJXt27d6rsPAA5gPb6uQNIauxrxwSc6FezOkdRPzpwtAwDqU62C3YEDB+q7DwAOMNpye52kXJv68EXl3cZjRLAD0PgwVywASdJlkjpZxoFwNqzVYUmJljGXPQHQGPl8EFxISIhuvPFG9evXT1FRUQoO9s6IxhhNnjz5rBsE0DAC8TInlX0i6fLy25epLKim2NYNADQ8n2aeiIqKUkJCgi666CIFBQXJGKOgoCBJ8tzm5AkgsGySdHX57SRJvWzsxVdXyXv3632S3rSpFwCwg0+7Yv/4xz8qNjZWkydP1vnnn6+goCCNGDFCvXr10j/+8Q99/fXXatOmjb97BVBPKk42qBCIW+skabOkY5Yxu2MBNDY+BbsxY8Zo8eLFeuedd5SVlSWp7JIou3bt0t133628vDzNmjXLr40CqD8j5f2PQaAGu1JJn1rGQyU1takXALCDT8GuQ4cO+vrrryVJxcXFkqRmzZp57l++fLl+/vOf+6E9AA3BumUrS9IGuxrxA2sorXzBZQBwO5+CXVpamlq2bClJys7OVlFRkc477zzP/UVFRYqKYrZGIBCESBphGcdJKrKpF39YJanYMmZ3LIDGxKdgt2vXLl144YWSyk6WSExM1MSJExUWFqbmzZtr/Pjx2rt3r18bBVA/+kuy/m9YoO6GrZChshNBKhDsADQmPgW7uLg43XLLLQoLC5MkzZs3T/369VNaWpp+/PFHXXHFFZo/f75fGwVQPyoHn5W2dOFf1nB6vqQYuxoBgAbm0+VOJCksLEyFhYWe8U033aS77rpLJSUl+uCDD7R06VJ/9QigHm2TdFH57a8l/dTGXvylt6TvLePHJc2zqRcAaEg+BzsAga+zpP2W8XOSnrenFb/bJ6lL+e21kobY1woANBi/TCnWrFkzr7NiAQSGyrthK8+3Gsis72WApHC7GgGABuRzsGvbtq1effVVpaSkKCcnRzk5OTp8+LBeffVVtWvXzp89Aqgn1mB3VNIWuxqpB9bj7EIlDbOrEQBoQD7tiu3atas2bNigjh07aufOndqxY4ckqVevXoqJiVFqaqoGDBig5ORkf/cLwE+aSzpR/l9JekfSJNu68b/K7+9tSb+yrx0AaDCmrvXhhx+avLw8c8MNN1S578YbbzR5eXnmww8/rPPzUhTVcDVaMsZStzigJ3/XJ5b3lyqZIAf0RFEUVc9V95UyMjLM3Llza7x/3rx5JiMjw+43RlHUaepVnQo9hZIJd0BP/q6H5B1e+zqgJ4qiqPosn46xM8Zo9+7dNd6/a9cuGWN8eWoADcR6fN0GlU0l5jaVL7bMxYoBuJ1PwW79+vUaPHhwjfcPGjRI69at86mhmJgYxcXFKScnR6mpqZo9e7ZCQ0Pr9By//e1vZYzRv/71L596ANyut05dCkQK/NkmarJf0n8tY4IdgMagzpv5unbtavbt22fmzp1r2rZt61netm1b86c//ckkJyebLl261Pl5IyMjTUpKilm3bp0ZPny4mTRpkklPTzcLFiyo9XO0b9/epKWlmSNHjph//etftm8SpSgn1v/IexdlrAN6qq+aXem9tnNATxRFUfVVtTor9ocffqiyrFWrVmrTpo0kKSMjQ5IUGRkpSTpx4oSys7PVo0ePMz21l6lTp+rJJ59U586dlZ6eLkm69957tXDhQnXu3FmpqalnfI53331Xxhh16dJFOTk5Gjt2bJ16ABqD9ZJ+Vn57r8qm3XKrn6ns/VaYKOlde1oBgHrXpDYPOnDgQIMcMzdq1CjFx8d7Qp0kLV26VK+//rqGDx+ud989/T/H11xzjW688UbFxMToH//4R323CwSkSEn9LWO37oatsElShsret1S2O5ZgB8CtahXsTnc8nT/Fxsbq7bff9lqWmZmp1NRUxcbGnnbd4OBg/eUvf9HMmTN15MiR+mwTCGgj5P3Fd3uwK5a0StLt5ePhKnv/xbZ1BAD1xy9TivlLVFSUZ7euVXp6uqKjo0+77kMPPaSWLVtq/vz5tX69sLAwtW7d2lOtWrWqa8tAwLGeQJAraZ1NfTQka3iNkHStXY0AQD2r1Ra7mnTv3l033HCDunfvLknau3ev/u///k979+71S3O11bZtW82YMUPjx49XUVFRrdebNm2annvuOc84KytLERER9dAh4AzBkkZZxmskFdjUS0NaKalUp/5PdowaR6AF0Dj5dNbFjBkzTGFhoSkpKfGqoqIi8/zzz/v0nEePHjUvvPBCleWHDh0ys2bNqnG91157zaxbt85ERER46vPPPzcrV640ERERJiQkpNr1wsLCTOvWrT3VqlUr289moaj6rH7yPkP0Pgf01FD1heV9b3dAPxRFUfVUdV9p0qRJpqSkxHz++edm7Nixpnv37qZ79+5m7Nix5rPPPjPFxcVmwoQJdX7e9evXm2XLlnktCw8PNyUlJad9voSEBHM6I0aMsPtDpihH1Ax5B7ufOKCnhqqnKr33bg7oiaIoqh6q7itt2bLFbNq0qdotYSEhIWbTpk1my5YtdX7eqVOnmqysLBMREeFZ9qtf/coUFRWZjh071rjepZdeagYOHOhViYmJZtOmTWbgwIEmKirK7g+ZohxR/9GpYLPVAf00ZF0u72D3Gwf0RFEUVQ9V95Vyc3PNI488UuP9jzzyiMnNza3z81ZcoDghIcEMGzbMTJw40aSlpVW5QHF8fLzZvXv3aZ8rISGBCxRTlKU6yjvYzHRATw1dKZb3v9IB/VAURfm7fDortrCw8LRnkLZu3VqFhYV1ft6MjAwNGTJExcXFWr58uV588UW99dZbeuyxx7weFxISoiZNzuq8D6DRGV1p7PbLnFRnheX2IEktbOoDAOpLrWaeqCwuLk4xMTG68sor9eOPP3rd17ZtW23ZskU7duzQyJEj/dUngLO0TNJN5bdPSGqnsjNFG5MbJX1kGf9cEjNKA3ATn4LdgAEDtGbNGmVnZ+uvf/2rtm/fLknq3bu3Jk2apNatW2vIkCHasGGDv/sF4IMwlYW5iu3sf5d0l33t2KaVyj6HsPLxG5IesK8dAKgXPu3Dvf76682+ffuqXO4kOTnZjBkzxvZ9zBRFnaqh8j6+7hcO6MmuirN8Dgcc0A9FUZQ/y6ctdhWCgoLUt29fdevWTVLZBYq/+eabBplXFkDtzZf0aPntEkltJaXb1o29fivpZcv4Uknf2dMKAPhdnYNdy5Yt9e2332rBggX685//XE9tAfCnXZIuKL+9QdIAG3uxWw9Juy3j6ZJm2dQLAPhbnc+Kzc3NVZs2bZSTk1Mf/QDwswt0KtRJjfNsWKs9Kgu6FcbU9EAACEA+Xe7kyy+/1BVXXOHvXgDUg8rBpbEHO8n7M7hKUrRdjQCAn/kU7KZOnarbbrtNEydO9HM7APzNGuwOStpmVyMOYg12IZK4MBMAt/Dp5Ik1a9aoS5cu6tq1q9LS0vTDDz/o5MmTXo8xxmjo0KH+6hOADypf3uN1SQ/a145jhKrsc2ldPv5/kn5pXzsA4Dc+Td/QvXt3GWN04MABSVL79u392hQA/ximU6FOYjdshSJJqyWNKx+PVNmWuxLbOgIA//Ap2FVc3gSAs1l3w+ZLWmtXIw70iU4Fu2iVHWu30b52AMAvfDrGDoDzBcl7ftgESSdreGxjtKLSmLNjAbiBT1vsKoSFhWnQoEHq3r27pLILFK9fv14FBQV+aQ6A7y6X1NEyZjestyOS/iOpb/l4jMquaQcAgc6nKSvuvvtuc+zYMVNcXOyZTqy4uNgcP37cTJgwwfYpNSiqsdfT8p5GrKsDenJaPV/pMzrPAT1RFEWdTfl0Vuxtt92mf/zjHzpw4IBef/11bd++XZLUu3dvPfDAA/rJT36iO++8U0uXLq3rUwPwky8l9Su/vV1Sbxt7caqfSvrKMn5A0hs29QIA/uBTsNu6datCQ0N11VVXKTs72+u+8PBwffXVVyooKNBll13mpzYB1EVble1qrDiI9iVJ/2NfO44VpLLPqV35+F+Sfm5fOwBw1nw6eSImJkaLFi2qEuokKSsrS4sWLVLPnj3PujkAvhkl7y83x9dVz0haaRkPkdTMpl4AwB98CnZHjhw57f3GGB09etSnhgCcPesZnhniMh6nYw29LSQNsqkPAPAHn4LdO++8o0mTJqlly5ZV7mvdurUmTZqkRYsWnXVzbtREUh+7m4CrNZE0wjKOk1RsUy+BoPLnw2VPAAQyny538vnnn+v666/Xtm3btHDhQiUlJUmSevXqpQcffFDHjx/X559/rgEDBlRZr7G6UtITkoarbBqjdpLSbO0IbnWNpAjLmN2wp5cpaYNObakbI+lh27oBgLPj08kTJSXeE+8YU/YUQUFBVZZVLDfGqEmTs7psXkAbIineMv6lyuanBPxtjqTfl98uldRB0jH72gkIT6jsBJMKF0raYVMvAHA2fEpakyZN8ncfrveZpGydmnR8jAh2qB/WXYlfi1BXG5/IO9iNEcEOQGDyaYsdfPOhTs1Nmaay3bFMOg5/6iop2TJ+RtIf7Gkl4OyVVDEL9jpJg+1rBQB8xlyxDch6rFPFpOOAP1U+8J/j62rP+lldK+/jFAEgUBDsGhCTjqO+WX+nUiUl2tVIALIGuyYqO9EJAAINwa4BVUw6XoFgB39qIe/dhyvEcRZ1sU7SScuY7yeAQESwa2DWrQKXSDrPrkbgOtfJe9YEdsPWTb6kNZbxKJUdhAwAgYRg18Aq/7EdbUsXcCPrFqZCSavtaiSAWb+f7VR2/UkACCQEuwb2taQfLWN298BfrL9Ln0nKsauRAMZxsAACHcGugTHpOOrDxfLerc9uWN8clLTNMibYAQg0BDsbMOk4/I3LnPiP9bPrq7KZOwAgUBDsbMCk4/A36+/QHkm77WrEBTgOFkAgI9jZoGLS8QoEO5yNaElXW8ZsrTs7X6hsZpgKfD8BBBKCnU2sf3y7SeplVyMIeCMkhVjGBLuzUyJplWU8TFKYTb0AQF0R7GxS+Y8vWwXgK+vvTo6k9XY14iLW72drSQPsagQA6ohgZ5MdkvZZxgQ7+CJY0kjLOF5l17DD2flUUqllzPcTQKAg2NmIScdxtq6S1MYyZjesf5yQ9KVlTLADECgIdjZi0nGcrcqBo/IFduE76/ezp6QedjUCAHVAsLNRgph0HGfH+juTKOmwXY24EMfBAghEBDsb5Utaaxkz6Tjq4ieSLrWM2Q3rX99KOmQZE+wABAKCnc2YdBy+qnzhXIKd/1l3bQ+U1MquRgCglgh2NmN3D3xl/V05JmmzXY24mPX7GSZpqF2NAEAtEexsxqTj8EVTSUMs48qX54B/rJFUYBnz/QTgdAQ7B2DScdTVQEktLWN2w9aPXEnrLGPmjQXgdAQ7B2DScdSVdctRsbynwIJ/Wb+f50q6zKY+AKA2CHYOwKTjqCvr78gmSRk29dEYcBwsgEBCsHOA6iYdD7WpFzhfjKTzLWN2w9avvZKSLGOCHQAnI9g5BJOOo7YqBwuCXf2zfsb9JJ1jVyMAcAYEO4dg0nHUlvV3Y7+k/9rVSCNiDXbBkkba1QgAnAHBziGYdBy1ES7vrblsrWsYGyRlWcZ8PwE4FcHOQax/pCsfRwVIVY+/JNg1jCJJcZbxCEkhNvUCAKdDsHMQzr7DmVh/J/IkJdjVSCNk/X5GSepvVyMAcBoEOwdh0nGcTpC8r3G4VmXhDg1jZaUx308ATkSwc5jKk463rOmBaHT6SmpvGbMbtmEdlfS1ZUywA+BEBDuHsf6xbiomHccpXObEftbP/CJJne1qBABqQLBzGCYdR02svwvfSzpgVyONGMfBAnA6gp3DMOk4qtNe0pWWMVvr7PEfSUcsY4IdAKch2DmQ9Y92JzHpOKRRlcYEO3sYeZ9EcZ2k5jb1AgDVIdg5ELt7UJn1dyBd0ia7GoHX97O5pMF2NQIA1SDYORCTjsMqVNJwy3iVpBKbeoG0WmUXLK7A9xOAkxDsHIpJx1HhWpVNJVaB3bD2ypL0uWVMsAPgJAQ7h2LScVSwBodSSZ/a1Qg8rN/PLpJ629UIAFRCsHMoJh1HBevP/itJx+1qBB4cBwvAqQh2DsWk45Ck7pJiLWN2wzrDTkk/WMYEOwBOQbBzMCYdB7NNOJf1Z9FfUqRNfQCAFcHOwZh0HNafeYqkrTb1gaqswa6JyraqA4DdCHYOxqTjjVtLSYMs4xU29YHqrVfZTDEV+H4CcAKCncMx6XjjNURSU8uY3bDOUiAp3jIeJf5BBWA/x/07FBMTo7i4OOXk5Cg1NVWzZ89WaGjoadfp0KGDZs+ercTERGVlZengwYP6+9//rs6dAz8GcfZd42X9WVcOEXAG6/fzHEk/tasRACjnqGAXGRmptWvXKiwsTOPGjdP06dN13333ad68eaddr2/fvho3bpyWLl2qG264QY899pguvvhibd68WeecE9iX9mXS8cZrtOV25d1+cIbKu8f5fgJwAuOUmjp1qsnOzjZRUVGeZffee68pKioyHTt2rHG9iIgIExIS4rWsU6dOpqSkxDz22GO2v6+zrbclY8rrpGSaO6Anqn7rUsvP3EjmEQf0RFVfWy0/p28c0A9FUY27HLXFbtSoUYqPj1d6erpn2dKlSxUcHKzhw4fXuF5mZqZKSrxnz0xJSdGxY8d07rnn1lu/DYVJxxsfLnMSOKw/m8slBf6/OAACmaOCXWxsrJKSkryWZWZmKjU1VbGxsTWsVb0LLrhA7du3144dO/zZoi2YdLzxsf6MK18MF85SOXSPrvZRANAwHBXsoqKilJGRUWV5enq6oqOj6/Rcr7zyilJSUvSPf/yjxseEhYWpdevWnmrVqlVdW24QTDreuLSRdJVlzNY6Z/tS0gnLmO8nADs5Ktj5y3PPPachQ4Zo/PjxOnnyZI2PmzZtmrKysjyVkpLSgF3WDZOONx4j5f3FJNg5W6mkTy3joZLCbOoFABwV7NLT0xUREVFleVRUlNLS0mr1HJMnT9azzz6r+++/X2vXrj3tY2fNmqXw8HBPderUyae+GwKXPWk8rD/byltr4UzW72crSQPtagRAo+eoYJeUlFTlWLrw8HB17NixyrF31bnxxhv12muv6emnn9aiRYvO+PjCwkJlZ2d7Kicnx+fe6xuTjjcOISrbYleh8vGVcKZPJVlP3+L7CcBOtp+aW1FTp041WVlZJiIiwrPsV7/61RkvdyLJDBw40OTl5ZmFCxfa/j7qq/6sU5dVKJJMpAN6ovxb18r7MieTHNATVbv63PJz2+2AfiiKarRlewOeioyMNCkpKSYhIcEMGzbMTJw40aSlpZkFCxZ4PS4+Pt7s3r3bM46NjTXp6enmu+++M1dffbXp16+fp7p37277+/JXDZf3H/3bHdAT5d+aVeln3N4BPVG1q6mVfnY9HdATRVGNsmxvwKtiY2PN6tWrTW5urjly5IiZM2eOCQ0N9XpMQkKCSU5O9ownTJhgarJo0SLb35O/qqlkcnTqD8diB/RE+be+s/x8v3ZAP1Tt62J5B7vfOaAniqIaXwWV30CAWC7phvLbxyW1V9lZeQh850k6YBk/L+k5e1qBjw6o7OcoSWtUdoYsADQkR508gTNj0nH3YraJwGf9mf1MUmu7GgHQaBHsAgyTjruX9Wd5VNIWuxqBz6zBLlTSMLsaAdBoEewCTIqkrZYxwc4dmkm6zjJeKY6RCERrJeVbxnw/ATQ0gl0AYtJx9xksqYVlzG7YwHRSUoJlPFpSkE29AGicCHYBiEnH3ce6ZadIUpxdjeCsWb+fHST1sasRAI0SwS4AfaWyM2IrsLsn8Fl/hhtUNpUYAhPT/wGwE8EuADHpuLtcKKmrZcxu2MC2T9J2y5hgB6AhEewCFJOOuweXOXEf68/wp5La2dUIgEaHYBegVolJx93C+rPbKynJrkbgN5XD+ShbugDQGBHsAlS6pE2WMcEuMEVKusYyZmudO2yUlGEZ8/0E0FAIdgHMGgJ6SOppVyPw2XBJTSxjgp07FMv7zObKP2cAqC8EuwDG2XeBz/ozOylpvV2NwO+s388ISdfa1QiARoVgF8C+l/ek8QS7wBIs72Ov1sh71gIEtpUqO4O9At9PAA2BYBfgrHPHMul4YLlSUlvLmN2w7nJM0teWMcEOQEMg2AU4Jh0PXJX/0K+o9lEIZNbvZy9J3exqBECjQbALcEw6HrisP6vvJB20qxHUG46DBdDQCHYBjknHA1NHec8hym5Yd0qUlGoZE+wA1DeCnQsw6XjgGV1pTLBzJyPvXeyDJLWwpxUAjQTBzgXY3RN4rD+jNElf2tUI6p31+9lM0hC7GgHQKBDsXGCfmHQ8kITJ+ySXT+U9PRzcZbWkQsuY7yeA+kSwcwkmHQ8cP5PUyjJmN6y75Uj6zDKuvBseAPyJYOcSTDoeOKx/2EtUtsUO7mb9fp4n6WK7GgHgegQ7l6g86ThbBZzLuivuS5UdYwd34zhYAA2FYOcSlScdHyEmHXeiHpJ6Wsbshm0cdpdXBYIdgPpCsHORypOOX2NXI6hR5T/oBLvGw/qzvlpStF2NAHA1gp2LMOm481l/JgdVNuMEGgdrsAtR2VZ1APA3gp2LMOm4s7WSNNAyZm7YxuUzlZ0hW4HvJ4D6QLBzGetWgQsldbWpD1Q1VGXXsKvAbtjGpVBl17SrMFL8AwzA//h3xWU4+865rD+LfElr7GoEtrF+P9tIusquRgC4FsHOZZh03Lmsl6BZJ+mkTX3APpV3v/P9BOBvBDuXqTzp+GAx6bgTXC7pXMuY3bCNU6qkbyxjgh0AfyPYuVDlScevs6sReHCZE1Sw/o/XpZJ+YlcjAFyJYOdCTDruPNafwQ5JyXY1AttVDvXMEgPAnwh2LlR50nGCnb3OkfRTy5itdY3bZpVdmqgC308A/kSwcykmHXeOUfL+ohHsGrdSSZ9axkMkNbWpFwDuQ7BzKS574hzWzz5T0ga7GoFjWL+fLSUNsqkPAO5DsHMpJh13hibynjoqTlKxTb3AOVbJ+/eA7ycAfyHYuRiTjtuvv6RIy5jdsJCkDEmbLGOCHQB/Idi5GJOO26/yH+yVtnQBJ7J+P7tLirWrEQCuQrBzMSYdt5/1M98s6Ue7GoHjcBwsgPpAsHMxJh23VxdJvS1jdsPC6r+S9lvGBDsA/sDfeZdj0nH7MNsEzsT6O3GtpHC7GgHgGgQ7l2PScftYP+sj8p4jFJC8g12opOF2NQLANQh2Lsek4/ZoLmmwZbxCkrGpFzhXgqQ8y5jvJ4CzRbBrBKxbBZh0vGFcp7JwV4HdsKhOnqS1lvEoSUE29QLAHQh2jQCTjjc865aXyiexAFbW72d7SVfY1QgAVyDYNQJfi0nHG5r1M/5cUrZdjcDxuOwJAH8i2DUCpfK+MC6TjteviyR1tozZDYvTOSDpe8uYYAfgbBDsGgkmHW84XOYEdWX9HblCUge7GgEQ8Ah2jQSTjjcc62e7R9IuuxpBwKgc/kfZ0gUANyDYNRKZkjZaxgS7+hElqb9lzNY61MYmSemWMd9PAL4i2DUiTDpe/0ZICrGMCXaojRKVbVWvMExlFywGgLoi2DUinH1X/6yfaY6k9XY1goBj/X6GSxpgVyMAAhrBrhHZLmmfZUyw869gSSMt43iVXcMOqI1PVXYGewW+nwB8QbBrZJh0vP70k3SOZcxuWNTFcUlfWcYEOwC+INg1Mkw6Xn8q/yFeYUsXCGTW72eMpPPtagRAwCLYNTIJkk5axmwV8B/rZ5ko6bBdjSBgcRwsgLNFsGtk8sWk4/Whk6TLLGN2w8IXWyWlWMYEOwB1RbBrhJh03P9GVxoT7OAr6y78gSqbKQYAaotg1wixu8f/rJ/hMUmb7WoEAc/6/WwqaahdjQAISAS7RuigpG2WMcHu7FT+41v5shVAXcRLKrCM+X4CqAuCXSPFpOP+U3l3GbthcTZy5X1h68q7+QHgdAh2jRSTjvuPdYtKsbynhgJ8Yf1+Vj4xBwBOh2DXSH0hKc0yZneP76yf3SZJGTb1AffgOFgAviLYNVJMOu4flS8iy25Y+MMPknZaxgQ7ALVFsGvEmHT87FX+g0uwg79Yf5cqT1cHADVxXLCLiYlRXFyccnJylJqaqtmzZys0tHbbkqZMmaL9+/fr5MmT2rRpk/r161fP3QY2Jh0/e9bPbL+k/9rVCFzHGuyCJY20qxEAAcc4pSIjI01KSopZt26dGT58uJk0aZJJT083CxYsOOO6U6ZMMfn5+ebRRx811113nfnwww9NZmam6datm+3vy8m1UTKmvJIc0E8gVbhkCi2f36sO6IlyT4VKJlOnfr/+4YCeKIoKiLK9AU9NnTrVZGdnm6ioKM+ye++91xQVFZmOHTvWuF7Tpk1NRkaGmTlzpmdZaGioSU5ONq+++qrt78vJNV2n/nAYyZzvgJ4CpW6u9NmNdkBPlLvqA536/UqTTIgDeqIoytnlqF2xo0aNUnx8vNLT0z3Lli5dquDgYA0fPrzG9fr376+IiAgtXbrUs6yoqEjLli3T6NFcBep0Kh8TNlZSCFWrut7yueVJSjjThw3UkfX7GaWy42Dt/r2nKKr6ckqgamJ3A1axsbF6++23vZZlZmYqNTVVsbGxp11PkpKSkryW79ixQ507d1azZs2Un5/v/4Zd4FtJhyT9pHw8v7xQN2tVFu4Af1pRacz/PADO9Y6kSXY3IYcFu6ioKGVkZFRZnp6erujo6NOul5+fr4KCAq/l6enpCg4OVlRUlFJTU6usFxYWpqZNm3rGpaWlys3N9f0NBKgP5YxfxkD2kd0NwJWOSlonqY/NfQA4M6f8z72jgl1DmzZtmp577jnP+NChQzrvvPPsa8gmj5YXAOcZbHcDAAKKU3YJSyrbwhYREVFleVRUlNLS0qpZ49R6zZo189r6VrFeaWmp1zF7VrNmzVJ4eLinYmNj1aRJ/WbdVq1aKTMzU61atarX13ETPrO64zOrOz4z3/C51R2fWd3xmdWeo7bYJSUlVTmWLjw8XB07dqxy/Fzl9aSya+B99913nuWxsbE6cOBAjcfXFRYWqrCw0A+d115QUJDCw8MVFBTUoK8byPjM6o7PrO74zHzD51Z3fGZ1x2dWe47aYrdy5UoNHTrUa6vdrbfeqtLSUsXFxdW43qZNm5SZmalbb73Vs6xJkyYaN26cVqyofPgxAACAe9l+zZWKqrhAcUJCghk2bJiZOHGiSUtLq3KB4vj4eLN7926vZVOmTDF5eXnmkUceMYMHDzb//Oc/HXmB4tatWxtjjGndurXtvQRK8ZnxmfGZObf43PjM+MwcV7Y34FWxsbFm9erVJjc31xw5csTMmTPHhIaGej0mISHBJCcnV1l36tSp5sCBAyYvL8988cUX5qqrrrL9/VSusLAw8+yzz5qwsDDbewmU4jPjM+Mzc27xufGZ8Zk5q4LKbwAAACDAOeoYOwAAAPiOYAcAAOASBLsGEhMTo7i4OOXk5Cg1NVWzZ89WaGio3W051i233KLly5fr4MGDysnJUWJioiZNYn6MumjZsqUOHjwoY4z69u1rdzuON378eH3zzTfKy8vTsWPHtGLFCjVr1szuthxr7Nix+vLLL5WVlaXDhw/r/fffV7du3exuyzHOP/98vfbaa0pMTFRRUZG2bdtW7ePuuece7dy5U3l5edq6davGjBnTwJ06x5k+s9atW+vZZ5/VV199pfT0dB05ckQff/yxLrroIps6diaCXQOIjIzU2rVrFRYWpnHjxmn69Om67777NG/ePLtbc6zHHntMJ0+e1OOPP66xY8dq5cqVevPNN/XMM8/Y3VrAePrpp+v9gttuMX36dC1YsEDvv/++RowYofvvv1/JyckKCQmxuzVHGjhwoD766CNt375dN910kx599FFdeumliouLIwyX6927t8aMGaM9e/Zo+/bt1T7m9ttv15tvvqn3339fo0aN0hdffKGPPvpI/fr1a+BuneFMn1nnzp11//33Ky4uTrfddpvuvfdeRURE6MsvvzztfPKNke1ncLi9pk6darKzs01UVJRn2b333muKiopMx44dbe/PidWmTZsqy9544w2TkZFhgoKCbO/P6RUTE2Oys7PNfffdZ4wxpm/fvrb35NTq2bOnKSwsNCNHjrS9l0Cp1157zfzwww9eywYNGmSMMebaa6+1vT8nlPXfqUWLFplt27ZVeUxSUpL5+9//7rVs48aN5pNPPrG9fyd+Zi1atDDNmzf3WtayZUtz/Phx88orr9jev1OKLXYNYNSoUYqPj/ea2mzp0qUKDg7W8OHDbezMuU6cOFFlWWJioiIiItSyZUsbOgosCxYs0Ouvv66dO3fa3YrjTZo0ScnJyfr000/tbiVghIaGKjs722tZZmamJDEzQDljzGnv79atm2JiYrR06VKv5e+9956GDBmisLCw+mzPkc70mZ08eVJ5eXley3Jzc7Vnzx6de+659dlaQCHYNYDY2NgqU6JlZmYqNTWVzcd1cO211+rQoUPKycmxuxVHu/nmm3XxxRdrxowZdrcSEK666ipt27ZNTz75pI4ePaqCggJt2LBBP/3pT+1uzbHeeecdXXjhhXrwwQcVHh6ubt266YUXXtA333yjjRs32t1eQKj4t7/y34YdO3aoadOmHK9YSxEREbrooou0Y8cOu1txDIJdA4iKilJGRkaV5enp6YqOjm74hgLQNddcozvuuENz5861uxVHa968uebNm6fp06dX2aKC6nXo0EHDhw/X+PHj9dBDD+nGG2+UMUZxcXFq27at3e050oYNG3TTTTfpxRdfVGZmpvbu3av27dtr1KhRKi0ttbu9gBAVFSVJVf42VOzZ4W9D7cyZM0fGGL3++ut2t+IYBDs4XqdOnfT+++8rISFBr7zyit3tONpTTz2lo0ePatGiRXa3EjCCg4PVunVr3XLLLfrwww+1cuVK/fznP1dQUJB+85vf2N2eI1199dVasmSJ3nzzTQ0ePFi33HKLgoOD9cknn3DyBBrMxIkTdd999+nXv/61UlJS7G7HMThlrgGkp6crIiKiyvKoqCilpaXZ0FHgiIiI0MqVK3XixAndfPPNZzwGozHr3LmzHn/8cd10002e37dWrVp5/tuyZUvl5uba2aIjpaen6/jx416XVkhPT1diYqJ69+5tY2fO9corr2jt2rV64oknPMu+/PJLHThwQHfffbfefPNNG7sLDBVb5iIiInT06FHP8ootefxtOL2RI0fqf//3fzVjxgwtXrzY7nYchS12DSApKanKsXTh4eHq2LFjleMrcEqzZs3073//WxERERo1apSysrLsbsnRunXrpqZNm2rFihXKyMhQRkaG/v3vf0uS1q1bp/j4eJs7dKb//ve/Nd7H1qfqXXjhhdq6davXspSUFB0/flznn3++PU0FmIp/+yv/bYiNjVVBQYH27t1rR1sBoV+/fvrggw/07rvv6tlnn7W7Hcch2DWAlStXaujQoV5b7W699VaVlpYqLi7Oxs6cKyQkREuXLlWvXr00cuRIHT582O6WHG/r1q0aNGiQVz366KOSpPvvv18PPfSQvQ061L///W+dc845uvTSSz3LoqOj1adPH/3nP/+xsTPn2r9/v/r06eO1rHPnzjrnnHO0b98+e5oKMMnJydq5c6duvfVWr+W333671qxZo6KiIps6c7ZevXrpk08+0dq1a/XAAw/Y3Y5j2X7NFbdXZGSkSUlJMQkJCWbYsGFm4sSJJi0tzSxYsMD23pxab7zxhjHGmN/97nemX79+XhUWFmZ7f4FSAwcO5Dp2Z6igoCDz1Vdfmd27d5vbbrvNjB071mzatMkcO3bMtG/f3vb+nFiPPPKIMcaYl19+2QwZMsTcdttt5rvvvjOpqakmOjra9v6cUM2bNzc333yzufnmm83atWvN/v37PeNzzjnHSDJ33HGHKSkpMc8995wZOHCgWbhwoSksLDRXXXWV7f078TNr27atOXDggDl48KAZPHiw19+FXr162d6/g8r2BhpFxcbGmtWrV5vc3Fxz5MgRM2fOHBMaGmp7X06t5ORkU5MuXbrY3l+gFMGudtWmTRuzePFik56ebnJzc82nn37KH4oz1P3332+2bt1qsrOzzeHDh82HH35oYmJibO/LKdWlS5ca/w0bOHCg53H33HOP2bVrl8nPzzfffvutGTNmjO29O/Uzq/j3rDoJCQm29++UCiq/AQAAgADHMXYAAAAuQbADAABwCYIdAACASxDsAAAAXIJgBwAA4BIEOwAAAJcg2AEAALgEwQ4AAMAlCHYA4GATJkyQMUYDBw70+3M/++yzMsaoS5cufn9uAPYg2AHAGfz2t7/VhAkT7G4DAM6IYAcAZ/Doo49q4sSJtrz2kiVL1KxZM3322We2vD6AwEKwAxDwgoOD1bx5c7vb8EmrVq1Oe39paakKCgpkDNN6Azgzgh2AehUaGqrf//73SkxMVG5urjIyMvT111/r17/+tecxHTt21Ny5c5WYmKi0tDTl5eXpv//9r/7nf/5HwcHe/0xVHHM2ZMgQPfXUU9qzZ4/y8/N12223SZKGDRum9957Tz/88INOnjyp9PR0rVq1Sj/72c+q7e/888/X22+/rYMHD6qgoEApKSlavny5+vTpI0kyxqhr164aNGiQjDGesh6X1rdvXy1btkzHjh1Tfn6+kpKSNH36dIWEhHi9VkJCgpKTk9WtWzf985//1IkTJ5SdnX3az6+6Y+wqlg0ePFiPP/645zPYuXOnxo8fX+U5goKCNHXqVO3du1d5eXnatm2b7rzzzhpfs0OHDlq4cKH279/v+UzeeOMNtW3b1vOY0aNHq6SkRG+99ZbXui1btlRSUpKOHDmi9u3bn/a9AfC/JnY3AMC9QkNDtWrVKg0ePFirVq3S3/72N+Xn5+viiy/WuHHj9Oqrr0qSLrnkEo0bN04fffSRfvjhB4WGhmrkyJGaPXu2unfvrgceeKDKc8+dO1ehoaF68803lZWVpZ07d0qSJk6cqOjoaC1evFiHDh1Sp06dNHnyZK1Zs0aDBw/Whg0bPM/Rt29frVmzRqGhofrrX/+q77//XtHR0Ro4cKD69++vb775RnfddZfmz5+v48ePa+bMmZ51jx07Jqks4Cxbtkx79uzRn/70J6Wlpenqq6/WjBkzdNlll3kCZ4VWrVpp/fr12rhxo5588km1a9fO58/3hRdeUPPmzfXGG2+ooKBADz74oN59913t2bNHmzZt8jxu3rx5evTRR7V+/XrNnz9f7dq106uvvqq9e/dWec7zzjtPX3zxhcLCwvTXv/5VP/zwg3r06KEHH3xQgwcP1hVXXKGsrCytWLFCL7/8sh577DGtXr1a77//viRp4cKFuuCCCzR69GgdPXrU5/cGwHeGoiiqPur3v/+9McaYmTNnVrkvKCjIc7tZs2bVrr948WJTXFxsOnTo4Fk2YcIEY4wxSUlJpnnz5lXWadGiRZVl7dq1M8eOHTOffPKJ1/Jt27aZvLw8c/HFF5+2v+TkZJOQkFDlMU2bNjWpqalm/fr1JiQkxOu+Rx991BhjzMCBAz3LEhISjDHG/OEPf6j1Z1jxfq3PU7Hsm2++MaGhoZ7l5557rsnPzzf/7//9P8+ynj17mpKSEhMfH2+Cg4M9yy+//HJTUlJijDGmS5cunuXLly83R48eNZ06dfLqo2/fvqaoqMg8++yznmWhoaHm66+/NhkZGaZbt27mrrvuMsYY89JLL9n+u0dRjbXYFQug3vzyl79UWlqaZsyYUeU+6zFj+fn5ntuhoaGKiopSmzZttGrVKoWEhOiKK66osv5rr72mvLy8KstPnjzpud2yZUtFR0erpKREX331lfr16+e577LLLtNFF12kRYsWadu2baftrybDhg1Thw4dtGjRIkVGRqpNmzaeWrFihSRp+PDhVdabO3fuGZ+7NhYuXKiioiLP+PDhw9q1a5cuuOACz7IbbrhBwcHBmjdvnkpLSz3LExMTtXr1aq/nCw8P1/XXX6+PP/5Y+fn5Xu9n37592rNnj9f7KSoq0u23366goCB99NFHWrhwob7++mtNmzbNL+8PQN2xKxZAvbngggu0detWFRQUnPZxISEhmjp1qsaPH68ePXpUOa4uKiqqyjq7du2q9rm6d++umTNnasSIEVXWswabivCTmJhYq/dSnV69ekmSFi1aVONjKh9n9uOPPyozM9Pn17SqblfqiRMnvI7/6969uyQpKSmpymO3b9+uESNGeMYxMTEKCQnR5MmTNXny5Gpf84cffqjSw2OPPaa33npLJ0+e1C9+8QsVFxf79H4AnD2CHQDbzZs3T4888ojee+89zZw5Uz/++KOKiorUp08fzZkzp0rQk7y3zFVo2bKlPvvsM7Vs2VIvv/yytm3bpuzsbJWWlmratGkaMmSIX/sOCgqSJD3xxBPaunVrtY85fPjwGfv2VUlJyWn7qquK9ZYsWaJ333232sdUt5V07NixkqQWLVooJiamSvgD0HAIdgDqza5duxQbG6uwsDAVFhbW+Li7775b69ev1y9+8Quv5T169KjT6w0ZMkSdOnXSpEmT9M4773jd98c//rFKb1LZLtkzqWm37O7duyVJubm5WrNmTZ16bSgVW/ViY2OrbOG78MILvcZ79uxRaWmpwsLCav1+fvOb3+iGG27QrFmzNG7cOL3zzju65JJLdOTIEf+8AQB1wjF2AOrN3//+d0VHR+upp5467eNKSkqqbGVq0aKFfve739Xp9Sq2YFV+rmHDhumqq67yWvbtt9/q+++/1z333FMl4FSWk5Oj6OjoKstXrVqlo0ePaurUqdXuLm7WrNkZr1NX3z7++GOVlpbqscce89ryefnll2vo0KFej01LS9OKFSs0btw4r+MRrc455xzP7UsuuUQvvfSS1q5dqyeffFJ33HGHwsPDtWTJEp+3GgI4O2yxA1Bv/vznP2vs2LF6+umndeWVVyouLk75+fnq3bu3YmJiNGzYMEnSBx98oAceeEDvvfee4uPj1b59e91zzz06ceJEnV5vw4YNSk1N1Z/+9Cd17dpVhw4d0mWXXaa7775b3333nS655BKvx0+aNElr1qzR5s2bPZc7iYyM1MCBA/Xpp5/qL3/5iyTpyy+/1K9+9SvNmDFDO3bsUGlpqf71r3/p5MmTGj9+vJYvX66dO3fq7bff1p49exQZGanY2FiNGzdON910k9avX++fD9QHO3fu1KuvvqqHH35Ya9eu1Ycffqh27drpN7/5jb799lvP9foqPPjgg9qwYYM+++wzLV68WImJiQoODlb37t11ww03aPHixXr++efVokULvffee8rKytJdd90lY4y2bt2qKVOm6OWXX9aUKVP04osv2vSugcbN9lNzKYpybzVt2tRMnz7dfP/99yYvL8+kp6ebzZs3mwcffNDzmObNm5s5c+aYffv2mby8PLNr1y4zZcoUc9111xljjJkwYYLnsdVd/sNaF198sVm5cqVJS0szWVlZJiEhwVx77bVm0aJFxpTtU/Wqnj17miVLlpjU1FRTUFBgUlJSzEcffWQuv/xyz2Patm1rPvjgA3PixIlqLxHSu3dvs2TJEnPo0CFTUFBgjhw5YjZu3GieeuopExUV5XlcQkKCSU5OrtPnd7rLnVT3GVT3GkFBQWb69Olm3759Jj8/32zbts3ceeed5tlnn63yXiSZNm3amDlz5pidO3d6fmbfffedefnll02vXr2MJPPXv/7VlJSUmFGjRlXp4V//+pcpLCw0P/3pT23//aOoxlZB5TcAAAAQ4DjGDgAAwCUIdgAAAC5BsAMAAHAJgh0AAIBLEOwAAABcgmAHAADgEgQ7AAAAlyDYAQAAuATBDgAAwCUIdgAAAC5BsAMAAHAJgh0AAIBLEOwAAABc4v8DjX3e7VFMr+4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probability = 1. - partial_matrix[-1, 1:] / len(hypothesis)\n",
    "plot(probability, ylim = (0, 1), xlabel = \"caracter index\", ylabel = \"probability (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
