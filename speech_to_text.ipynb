{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for the `Speech-To-Text (STT)` API\n",
    "\n",
    "This API allows you to easily perform prediction / search on audios / videos by  automatically loading models and calling associated function. \n",
    "\n",
    "You can identify models either by their name or by their associated language. To associate a model to a language, go to `models/stt/__init__.py` in the `_pretrained` variables (at the end of the file) you can see `'en' : 'whisper'`. It means that when you are calling a function with `lang = 'en'`, it will load the `whisper` model to perform prediction. \n",
    "\n",
    "Do not forget to initialize `whisper` ! (cf cell below)\n",
    "\n",
    "Note : prediction / search can be performed either on audios, either on videos !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build whisper\n",
    "\n",
    "[Whisper](https://github.com/openai/whisper) is a multilingual `Speech-to-Text` model trained by `OpenAI`.\n",
    "\n",
    "**WARNING** : `pytorch` is required to convert the weigths, as the official project is made with `pytorch`. Do not forget to install it : `pip install torch`. A GPU version is **not** required ;)\n",
    "\n",
    "**Important Note** : the tokenizer is now copied from the `transformers` library, as the new official `openai`'s code is using their custom `tiktoken` tokenizer. This means that the 2 tokenizers are not *exactly* identical, but are compatible as the differences do not have any impact on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== whisper ==========\n",
      "Sub model stt_model\n",
      "- Inputs \t: unknown\n",
      "- Outputs \t: unknown\n",
      "- Number of layers \t: 2\n",
      "- Number of parameters \t: 72.594 Millions\n",
      "- Model not compiled\n",
      "\n",
      "Transfer-learning from : base\n",
      "Already trained on 0 epochs (0 steps)\n",
      "\n",
      "- Language : multi\n",
      "- Vocabulary (size = 50364) : ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ...]\n",
      "- Audio rate : 16000\n",
      "- # mel channels : 80\n",
      "- Use CTC decoder : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.stt import Whisper\n",
    "\n",
    "model = Whisper(pretrained = 'base', lang = 'multi', nom = 'whisper')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction API\n",
    "\n",
    "The prediction API is very simple to use : pass the audio filename(s), and the model you want (or the audio language) and that's it !\n",
    "\n",
    "The prediction splits the audio by *frames* of a given amount of time (default to 30sec), and predicts the text for each frame. Then it concatenates all the texts to build the complete transcription of the audio file ! Note that `Whisper` also splits each *frame* into sub-frames that are given in the output of the function. This may be useful to search a span of text, or even complete / correct the transcription ! \n",
    "\n",
    "This demonstration is performed on a short and clean audio. Nevertheless, `Whisper` has been trained on large scale datasets, and is able to transcribe audios in many languages, even in noisy or low quality audios !\n",
    "\n",
    "**[NEW]** The inference method of `Whisper` is now compatible with the [XLA](https://www.tensorflow.org/xla) optimization ! This makes the model much faster than in eager (sequential) model, at the cost of a much slower 1st call, as it needs to compute the execution graph. If you want to run in eager mode, pass `run_eagerly = True`, or `use_xla = False` to use the graph mode without XLA optimization (see the `CHANGELOG` for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timers for logger timer :\n",
      "- predict : 496 ms\n",
      "  - initialization : 0 μs\n",
      "  - pre_processing : 0 μs\n",
      "  - loading audio : 119 ms\n",
      "  - segment processing : 10 ms\n",
      "  - detect_language : 314 ms\n",
      "    - pre_processing : 12 ms\n",
      "    - language detection : 33 ms\n",
      "  - inference : 50 ms\n",
      "    - Transformer inference : 50 ms\n",
      "  - post_processing : 0 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('audio_en.wav',\n",
       "  {'filename': 'audio_en.wav',\n",
       "   'text': 'The streets were narrow and unpaid but very fairly clean.',\n",
       "   'alignment': [{'id': -1,\n",
       "     'start': 0.0,\n",
       "     'end': 4.0,\n",
       "     'num': 0,\n",
       "     'time': 4.0,\n",
       "     'text': 'The streets were narrow and unpaid but very fairly clean.',\n",
       "     'tokens': array([  440,  8481,   645,  9432,   293,   517, 35035,   457,   588,\n",
       "             6457,  2541,    13]),\n",
       "     'score': 0}]})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loggers import set_level\n",
    "from models.stt import predict\n",
    "from utils.audio import display_audio\n",
    "\n",
    "set_level('time')\n",
    "\n",
    "filename = 'audio_en.wav'\n",
    "pred = predict(filename, model = 'whisper', overwrite = True, save = False)\n",
    "\n",
    "#display_audio(filename)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search keyword in audio\n",
    "\n",
    "The `search` function allows you to search a keyword in an audio / video and get all timestamps where this keyword has been found (with a given probability threshold). As the model is relatively poor for *transcription*, I use **partial alignment** to get the probability of the word at each position (cf README.md for explaination on partial alignment). \n",
    "\n",
    "Next, to find the approximately timestamp where the word has been pronounced, I get the start of the *frame* (as audio are splitted in frames of *n* sec) and get the relative position of the word in the frame's text. \n",
    "\n",
    "In the below example, the *unpaved* word seems to be approximately in themiddle of the text so I suggest it is approximately at themiddle of the audio : the estimated timestamp is at 1.9sec which is approximately the middle of the 4sec audio !\n",
    "\n",
    "In this case the estimation is quite good as the frame is short (4sec) but this estimation is worst when audios are longer (with 30sec frame by default). It is the reason why, when displaying audio timestamps, I have added the `before` argument which wil display audio *n* sec before the predicted timestamp (by default to 2.5sec but you can increase it to 5 or 7.5sec if audios are longer / sparse (with silences)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name : stt_en_conformer_transducer_medium\n",
      "Timers for logger timer :\n",
      "- search : 0.004 sec\n",
      "  - predict : 0.003 sec\n",
      "  - distance : 0.001 sec\n",
      "Result for searching keyword 'unpaved' :\n",
      "Number of files : 1 / 1\n",
      "Total number of occurences : 1\n",
      "Files : Annotation of file ../__test_datas/audio_en.wav :\n",
      "- Total annotation time : 4.000 sec\n",
      "- Number of alignments : 1 (1 sub-parts)\n",
      "- Speakers (n = 1) : [-1]\n",
      "\n",
      "Occurences of 'unpaved' (1, threshold = 80.00%) :\n",
      "- Timestamp 1.895 sec (p = 100.00 %) : [...]  unpaved but v [...]\n",
      "\n",
      "pretrained_models\\stt_en_conformer_transducer_medium\\search\\map.json\n",
      "Filename is in processed file : True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from utils import load_json\n",
    "from models.model_utils import get_model_dir\n",
    "from models.stt import search, get_model_name\n",
    "\n",
    "model_name = get_model_name(lang = 'en')\n",
    "filename = '../__test_datas/audio_en.wav'\n",
    "\n",
    "print(\"Model name : {}\".format(model_name))\n",
    "r = search('unpaved', filename, model = model_name)\n",
    "print(r)\n",
    "print(get_model_dir(model_name, 'search', 'map.json'))\n",
    "print(\"Filename is in processed file : {}\".format(filename in load_json(get_model_dir(model_name, 'outputs', 'map.json'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.display(before = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pretrained DeepSpeech\n",
    "\n",
    "Note that the `pretrained_jasper` is the best compared to the `pretrained_deep_speech` but it is much bigger. If you want to use the `DeepSpeech` model, you first have to build it. \n",
    "\n",
    "Simply run these 2 lines and change, in the function above, the `lang = 'en'` by `model = 'pretrained_deep_speech'` and that's it ! All functions will use the `DeepSpeech2` model !\n",
    "\n",
    "Note : it will automatically download pretrained weights in `pretrained_models/pretrained_weights/` foler (400Mb) so it can take some time depending on your internet connection bandwith ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stt import DeepSpeech\n",
    "model = DeepSpeech.from_deep_speech_pretrained()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stt import Jasper\n",
    "model = Jasper.from_jasper_pretrained()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit distance demonstration\n",
    "\n",
    "This example illustrates with longer example the **edit distance** with partial alignment for searching keyword in bad-spelled text (as described in the README file). \n",
    "\n",
    "The objective is to find *cat* in the text *the ct is here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance without partial alignment :\n",
      "          t    h    e         c    t         i    s           h     e     r     e\n",
      "   0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  10.0  11.0  12.0  13.0  14.0\n",
      "c  1.0  1.0  2.0  3.0  4.0  4.0  5.0  6.0  7.0  8.0   9.0  10.0  11.0  12.0  13.0\n",
      "a  2.0  2.0  2.0  3.0  4.0  5.0  5.0  6.0  7.0  8.0   9.0  10.0  11.0  12.0  13.0\n",
      "t  3.0  2.0  3.0  3.0  4.0  5.0  5.0  6.0  7.0  8.0   9.0  10.0  11.0  12.0  13.0\n",
      "Edit distance with partial alignment :\n",
      "          t    h    e         c    t         i    s         h    e    r    e\n",
      "   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "c  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "a  2.0  2.0  2.0  2.0  2.0  1.0  1.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0\n",
      "t  3.0  2.0  3.0  3.0  3.0  2.0  1.0  2.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
      "Best alignment :  ct\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from loggers import set_level\n",
    "from utils import plot, set_display_options\n",
    "from utils.distance import edit_distance\n",
    "\n",
    "set_level('info')\n",
    "set_display_options()\n",
    "\n",
    "truth = 'the ct is here'\n",
    "hypothesis = 'cat'\n",
    "\n",
    "print(\"Edit distance without partial alignment :\")\n",
    "dist, matrix = edit_distance(hypothesis, truth, partial = False, return_matrix = True, normalize = False, verbose = True)\n",
    "\n",
    "print(\"Edit distance with partial alignment :\")\n",
    "partial_dist, partial_matrix = edit_distance(hypothesis, truth, partial = True, return_matrix = True, normalize = False, verbose = True)\n",
    "\n",
    "start_idx = np.argmin(partial_matrix[-1, 1:]) + 1 - len(hypothesis)\n",
    "print(\"Best alignment : {}\".format(truth[start_idx : start_idx + len(hypothesis)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probability = 1. - partial_matrix[-1, 1:] / len(hypothesis)\n",
    "plot(probability, ylim = (0, 1), xlabel = \"caracter index\", ylabel = \"probability (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
