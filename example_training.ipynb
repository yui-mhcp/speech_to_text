{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STT model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.stt import DeepSpeech, Jasper, TransformerSTT\n",
    "from datasets import get_dataset, train_test_split, prepare_dataset, test_dataset_time\n",
    "from utils import plot_spectrogram\n",
    "from utils.text import get_symbols\n",
    "from utils.audio import display_audio, load_audio, load_mel\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "model_name = \"siwis_deep_speech\"\n",
    "\n",
    "\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))\n",
    "print(\"Available GPU's ({}) : {}\".format(len(gpus), gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaners = ['french_cleaners']\n",
    "\n",
    "vocab = get_symbols('fr', maj = False, ponctuation = 2)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSpeech.build_pretrained_deep_speech(\n",
    "    nom = model_name, lang = 'fr', vocab = vocab, cleaners = cleaners\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'embedding_dim'      : 512,\n",
    "    'encoder_num_layers' : 4,\n",
    "    'encoder_mha_num_heads' : 2,\n",
    "    'decoder_num_layers' : 1,\n",
    "    'decoder_mha_num_heads' : 2,\n",
    "    'encoder_enc_mha_num_heads' : 2,\n",
    "}\n",
    "model = TransformerSTT(lang = 'fr', nom = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.text_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSpeech(nom = model_name)\n",
    "\n",
    "lr_config = {\n",
    "    'name' : 'WarmupScheduler',\n",
    "    'maxval' : 1e-3,\n",
    "    'minval' : 1e-4,\n",
    "    'factor' : 256,\n",
    "    'warmup_steps' : 275 * 10\n",
    "}\n",
    "lr_config = 1e-3\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam', \n",
    "    optimizer_config = {\n",
    "        'lr' : lr_config\n",
    "    }\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'siwis'\n",
    "dataset = get_dataset(dataset_name)\n",
    "\n",
    "train, valid = None, None\n",
    "\n",
    "print(\"Dataset length : {}\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Classic hyperparameters \"\"\"\n",
    "epochs     = 25\n",
    "batch_size = 32\n",
    "valid_batch_size = 2 * batch_size\n",
    "train_prop = 0.9\n",
    "train_size = int(len(dataset) * train_prop)\n",
    "valid_size = min(len(dataset) - train_size, 250 * valid_batch_size)\n",
    "\n",
    "shuffle_size    = 1024\n",
    "pred_step       = -10 # make a prediction after every epoch\n",
    "augment_prct    = 0.1\n",
    "\n",
    "\"\"\" Custom training hparams \"\"\"\n",
    "trim_audio      = False\n",
    "reduce_noise    = False\n",
    "trim_threshold  = 0.075\n",
    "max_silence     = 0.25\n",
    "trim_method     = 'window'\n",
    "trim_mode       = 'start_end'\n",
    "\n",
    "trim_mel     = False\n",
    "trim_factor  = 0.6\n",
    "trim_mel_method  = 'max_start_end'\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "\n",
    "# this is to normalize dataset usage so that you can use a pre-splitted dataset or not\n",
    "# without changing anything in the training configuration\n",
    "if train is None or valid is None:\n",
    "    train, valid = train_test_split(\n",
    "        dataset, train_size = train_size, valid_size = valid_size, shuffle = True\n",
    "    )\n",
    "\n",
    "print(\"Training samples   : {} - {} batches\".format(\n",
    "    len(train), len(train) // batch_size\n",
    "))\n",
    "print(\"Validation samples : {} - {} batches\".format(\n",
    "    len(valid), len(valid) // valid_batch_size\n",
    "))\n",
    "\n",
    "model.train(\n",
    "    train, validation_data = valid,\n",
    "\n",
    "    epochs = epochs, batch_size = batch_size, valid_batch_size = valid_batch_size,\n",
    "    \n",
    "    pred_step = pred_step, shuffle_size = shuffle_size, augment_prct = augment_prct,\n",
    "    \n",
    "    trim_audio = trim_audio, reduce_noise = reduce_noise, trim_threshold = trim_threshold,\n",
    "    max_silence = max_silence, trim_method = trim_method, trim_mode = trim_mode,\n",
    "    \n",
    "    trim_mel = trim_mel, trim_factor = trim_factor, trim_mel_method = trim_mel_method,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_dataset_config(batch_size = 32, is_validation = False, shuffle_size = 0)\n",
    "ds = prepare_dataset(dataset, ** config, debug = True)\n",
    "\n",
    "test_dataset_time(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros((model.audio_rate * 10,))\n",
    "mel = model.mel_fn(a)\n",
    "print(\"Mel shape for 10 audio sec : {}\".format(tf.shape(mel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
